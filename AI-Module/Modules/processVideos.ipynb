{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import subprocess\n","\n","def process_videos_in_folder(folder_path):\n","    for file_name in os.listdir(folder_path):\n","        if file_name.startswith(\"filtered_\"):\n","            print(f\"El video {file_name} ya fue procesado\")\n","            continue\n","        if file_name.endswith(\".mp4\"):\n","            input_path = os.path.join(folder_path, file_name)\n","            output_path = os.path.join(folder_path, f\"filtered_{file_name}\")\n","            \n","            # Comando ffmpeg\n","            command = [\n","                \"ffmpeg\", \n","                \"-i\", input_path, \n","                \"-vf\", r\"select=not(mod(n\\,3))\", \n","                \"-vsync\", \"vfr\", \n","                \"-c:v\", \"libx264\", \n","                output_path\n","            ]\n","            \n","            try:\n","                subprocess.run(command, check=True)\n","                print(f\"Video procesado: {file_name}\")\n","                os.remove(input_path)\n","            except subprocess.CalledProcessError as e:\n","                print(f\"Error procesando el video {file_name}: {e}\")"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["c:/Users/matia/OneDrive/Escritorio/SignAI-ML/AI-Module/\n","['BERT', 'CNN-LSTM', 'Extra', 'Modules', 'Resources', 'Tests', '__init__.py']\n"]}],"source":["import sys\n","\n","base_path = os.getcwd().split(\"\\\\\")\n","project_directory = r\"\"\n","for part in base_path:\n","    if part != \"Modules\":\n","        project_directory += part\n","        project_directory += r\"/\"\n","modules_directory = r\"Modules\"\n","\n","modules_path = project_directory + modules_directory\n","\n","sys.path.append(modules_path)\n","print(project_directory)\n","print(os.listdir(project_directory))"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["root_vids = project_directory + \"Resources/Videos/raw_videos\"\n","root_translation_csv = project_directory + \"Resources/Translations\""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def obtain_paths(root, extension):\n","    paths = []\n","\n","    for filename in os.listdir(root):\n","        if filename.endswith(extension):\n","            paths.append(os.path.join(root, filename))\n","    return paths"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import KeyFrameExtractorClass\n","import Points2VecClass\n","import cv2\n","import VideoFormaterClass"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["vids:4\n","translation_csv: c:/Users/matia/OneDrive/Escritorio/SignAI-ML/AI-Module/Resources/Translations\\how2sign_train.csv\n"]}],"source":["vids = obtain_paths(root_vids, '.mp4')\n","translation_csv = obtain_paths(root_translation_csv, '.csv')[1]\n","print(\"vids:\" + str(len(vids)))\n","print(\"translation_csv: \" + str(translation_csv))"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def make_df_video(video_paths, csv_path, type):\n","    kfe = KeyFrameExtractorClass.KeyFrameExtractor()\n","    videoFormater = VideoFormaterClass.VideoFormater()\n","    normalizer = Points2VecClass.Point2Vec(4)\n","    translationDf = videoFormater.csvToTranslationDf(csv_path)\n","    if not os.path.exists(project_directory + f\"Resources/Datasets/{type}\"):\n","        os.mkdir(project_directory + f\"Resources/Datasets/{type}\")\n","    for index, path in enumerate(video_paths):\n","        print(\"Processing video: \", index)\n","        video = cv2.VideoCapture(path)\n","        file_name = path.split(os.path.sep)[-1].split(\".mp4\")[0].split(\"filtered_\")[1]\n","        print(file_name)\n","        translation_filter = translationDf[\"VIDEO_NAME\"] == file_name\n","        translation = translationDf[translation_filter][\"SENTENCE\"].iloc[0]\n","        video_points = kfe.extractKeyFrames(return_frame=False, draw=False, video=video)\n","        landmarks = normalizer.land2vec(video_points)\n","        cant_keyframes = len(video_points)\n","        dict = {\"points\": landmarks, \"translation\": translation, \"id\": index, \"len_keyframes\": cant_keyframes}\n","        dataFrame = videoFormater.formatVideo(dict)\n","        videoFormater.concatAndExportVideos(dataFrame, project_directory + f\"Resources/Datasets/{type}/{file_name}.csv\")"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def processVideos(paths, csv_path, folder_name, root_vids):\n","    print(paths, csv_path, folder_name)\n","    process_videos_in_folder(root_vids)\n","    make_df_video(paths, csv_path, folder_name)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['c:/Users/matia/OneDrive/Escritorio/SignAI-ML/AI-Module/Resources/Videos/raw_videos\\\\filtered_videoprueba1.mp4', 'c:/Users/matia/OneDrive/Escritorio/SignAI-ML/AI-Module/Resources/Videos/raw_videos\\\\filtered_videoprueba2.mp4', 'c:/Users/matia/OneDrive/Escritorio/SignAI-ML/AI-Module/Resources/Videos/raw_videos\\\\filtered_videoprueba3.mp4', 'c:/Users/matia/OneDrive/Escritorio/SignAI-ML/AI-Module/Resources/Videos/raw_videos\\\\filtered__2FBDaOPYig-5-rgb_front.mp4'] c:/Users/matia/OneDrive/Escritorio/SignAI-ML/AI-Module/Resources/Translations\\how2sign_train.csv videos\n","El video filtered_videoprueba1.mp4 ya fue procesado\n","El video filtered_videoprueba2.mp4 ya fue procesado\n","El video filtered_videoprueba3.mp4 ya fue procesado\n","El video filtered__2FBDaOPYig-5-rgb_front.mp4 ya fue procesado\n","Processing video:  0\n","videoprueba1\n"]},{"ename":"IndexError","evalue":"single positional indexer is out-of-bounds","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprocessVideos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslation_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvideos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_vids\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[8], line 4\u001b[0m, in \u001b[0;36mprocessVideos\u001b[1;34m(paths, csv_path, folder_name, root_vids)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(paths, csv_path, folder_name)\n\u001b[0;32m      3\u001b[0m process_videos_in_folder(root_vids)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmake_df_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_name\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[12], line 14\u001b[0m, in \u001b[0;36mmake_df_video\u001b[1;34m(video_paths, csv_path, type)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(file_name)\n\u001b[0;32m     13\u001b[0m translation_filter \u001b[38;5;241m=\u001b[39m translationDf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVIDEO_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m file_name\n\u001b[1;32m---> 14\u001b[0m translation \u001b[38;5;241m=\u001b[39m \u001b[43mtranslationDf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtranslation_filter\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSENTENCE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m video_points \u001b[38;5;241m=\u001b[39m kfe\u001b[38;5;241m.\u001b[39mextractKeyFrames(return_frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, draw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, video\u001b[38;5;241m=\u001b[39mvideo)\n\u001b[0;32m     16\u001b[0m landmarks \u001b[38;5;241m=\u001b[39m normalizer\u001b[38;5;241m.\u001b[39mland2vec(video_points)\n","File \u001b[1;32mc:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n","File \u001b[1;32mc:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"]}],"source":["processVideos(vids, translation_csv, \"videos\", root_vids)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def joincsvs():\n","    pass"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":2}
