{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">1. Import Required Libraries & Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModel, BertTokenizer\n",
    "\n",
    "#specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if Pytorch is using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available(), torch.cuda.device_count(), torch.cuda.current_device(), torch.cuda.device(0), torch.cuda.get_device_name(0), device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos = pd.read_csv(\"/app/AI-Module/Resources/Datasets/how2sign.csv\", usecols=[\"translation\", \"id\"])\n",
    "#df_videos = pd.read_csv(\"C:/Users/48519558/Desktop/SignAI-ML/AI-Module/Resources/Datasets/how2sign.csv\", usecols=[\"translation\", \"id\"])\n",
    "#df_videos = pd.read_csv(\"D:/SignAI-ML/AI-Module/Resources/Datasets/how2sign.csv\", usecols=[\"translation\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_videos = pd.read_csv(\"D:/Sprinfil/Dataset/how2sign.csv\")\n",
    "# df_videos = df_videos.sort_values([\"id\"]).reset_index().drop([\"index\"], axis=1)\n",
    "# df_videos.head()\n",
    "# import ast\n",
    "# points = df_videos[\"points\"]\n",
    "# for index, point in enumerate(points):\n",
    "#     print(index)\n",
    "#     points.at[index] = ast.literal_eval(point)\n",
    "# type(points.iloc[0])\n",
    "# df_videos[\"points\"] = points\n",
    "# df_videos.head()\n",
    "# for index, item in enumerate(points):\n",
    "#     item = np.array(item)\n",
    "#     print(index, item.shape)\n",
    "#     item_with_index = np.array((item, index), dtype=object)\n",
    "#     points.iloc[index]=item\n",
    "#     np.save(f\"{index}.npy\", item_with_index)\n",
    "# df_videos[\"points\"] = points\n",
    "# df_videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puntos_folder = \"/app/AI-Module/Resources/Datasets/Points\"\n",
    "#puntos_folder = \"C:/Users/48519558/Desktop/SignAI-ML/AI-Module/Resources/Datasets/Points\"\n",
    "#puntos_folder = \"D:/SignAI-ML/AI-Module/Resources/Datasets/Points\"\n",
    "files = [puntos_folder + \"/\" + file for file in os.listdir(puntos_folder)]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_points(files):\n",
    "    for file in files:\n",
    "        item_with_index = np.load(file, allow_pickle=True)\n",
    "        item = item_with_index[0].astype(np.float16)\n",
    "        index = item_with_index[1]\n",
    "        yield item, index\n",
    "\n",
    "puntos_list = []\n",
    "ids_list = []\n",
    "\n",
    "for item, index in load_points(files):\n",
    "    puntos_list.append(item)\n",
    "    ids_list.append(index)\n",
    "\n",
    "df_puntos = pd.DataFrame({\n",
    "    'points': puntos_list,\n",
    "    'id': ids_list\n",
    "})\n",
    "df_puntos = df_puntos.sort_values([\"id\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos = df_videos.merge(df_puntos, on=\"id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = df_videos['points'].apply(lambda x: len(x)).max()\n",
    "print(max_len)\n",
    "df_videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(max_frames, point_series: pd.Series):\n",
    "    for i in range(len(point_series)):\n",
    "        current_length = len(point_series[i])\n",
    "        if current_length < max_frames:\n",
    "            padding = np.full(\n",
    "                (max_frames - current_length, 2172), \n",
    "                -1,\n",
    "                dtype=np.float16\n",
    "            )\n",
    "            padding[:, 3::4] = 0\n",
    "            point_series[i] = np.concatenate((point_series[i], padding), axis=0)\n",
    "    return point_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos['points'] = add_padding(max_len, df_videos['points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_df = df_videos['points'].to_frame()\n",
    "y_df = df_videos['translation'].to_frame()\n",
    "seed = 31991\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=(100/500), random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=(100/400), random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(), y_train.head(), X_val.head(), y_val.head(), X_test.head(), y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "globals().pop(\"df_videos\", None)\n",
    "globals().pop(\"puntos_list\", None)\n",
    "globals().pop(\"ids_list\", None)\n",
    "globals().pop(\"df_puntos\", None)\n",
    "globals().pop(\"X_df\", None)\n",
    "globals().pop(\"item\", None)\n",
    "globals().pop(\"y_df\", None)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">3. Import Bert - base- uncased</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T11:49:24.18724Z",
     "iopub.status.busy": "2021-05-20T11:49:24.186902Z",
     "iopub.status.idle": "2021-05-20T11:50:15.137513Z",
     "shell.execute_reply": "2021-05-20T11:50:15.135994Z",
     "shell.execute_reply.started": "2021-05-20T11:49:24.187212Z"
    }
   },
   "outputs": [],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_label_train = tokenizer.batch_encode_plus(\n",
    "    y_train['translation'].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_label_val = tokenizer.batch_encode_plus(\n",
    "    y_val['translation'].tolist(),\n",
    "    padding = True,\n",
    "    truncation = True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_label_test = tokenizer.batch_encode_plus(\n",
    "    y_test['translation'].tolist(),\n",
    "    padding = True,\n",
    "    truncation = True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u><h2 style=\"font-size:170%; font-family:cursive;\">What is the maximum sequence length of the input?</h2></u>\n",
    "\n",
    "<p style=\"font-size:150%; font-family:verdana;\">The maximum sequence length of the input = 512</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">5. List to Tensors</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_mask_from_points(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    # Crear una m치scara inicial llena de unos\n",
    "    mask = torch.ones(tensor.size(), dtype=torch.int8, device=tensor.device)\n",
    "\n",
    "    # Reestructurar el tensor para facilitar la verificaci칩n de condiciones\n",
    "    points = tensor.view(tensor.size(0), tensor.size(1), -1, 4)  # Cambiar la forma para agrupar por 4\n",
    "    conditions = (points[:, :, :, 0] == -1) & (points[:, :, :, 1] == -1) & (points[:, :, :, 2] == -1) & (points[:, :, :, 3] == 0)\n",
    "\n",
    "    # Aplicar la condici칩n directamente a la m치scara\n",
    "    mask.view(tensor.size(0), tensor.size(1), -1, 4)[conditions] = 0\n",
    "\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:16:52.707444Z",
     "iopub.status.busy": "2021-05-20T12:16:52.707085Z",
     "iopub.status.idle": "2021-05-20T12:16:52.744645Z",
     "shell.execute_reply": "2021-05-20T12:16:52.743449Z",
     "shell.execute_reply.started": "2021-05-20T12:16:52.707415Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert lists to tensors\n",
    "gc.collect()\n",
    "train_np = np.array(X_train['points'].tolist(), dtype=np.float16)\n",
    "train_seq = torch.tensor(train_np, dtype=torch.float16)\n",
    "gc.collect()\n",
    "train_mask = create_attention_mask_from_points(train_seq)\n",
    "train_y = tokens_label_train['input_ids']\n",
    "globals().pop(\"X_train\", None)\n",
    "globals().pop(\"train_np\", None)\n",
    "globals().pop(\"y_train\", None)\n",
    "globals().pop(\"tokens_label_train\", None)\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "val_np = np.array(X_val['points'].tolist(), dtype=np.float16)\n",
    "val_seq = torch.tensor(val_np, dtype=torch.float16)\n",
    "gc.collect()\n",
    "val_mask = create_attention_mask_from_points(val_seq)\n",
    "val_y = tokens_label_val['input_ids']\n",
    "globals().pop(\"X_val\", None)\n",
    "globals().pop(\"val_np\", None)\n",
    "globals().pop(\"y_val\", None)\n",
    "globals().pop(\"tokens_label_val\", None)\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "test_np = np.array(X_test['points'].tolist(), dtype=np.float16)\n",
    "test_seq = torch.tensor(test_np, dtype=torch.float16)\n",
    "gc.collect()\n",
    "test_mask = create_attention_mask_from_points(test_seq)\n",
    "test_y = tokens_label_test['input_ids']\n",
    "globals().pop(\"X_test\", None)\n",
    "globals().pop(\"test_np\", None)\n",
    "globals().pop(\"y_test\", None)\n",
    "globals().pop(\"tokens_label_test\", None)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">6. Data Loader</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:16:54.073069Z",
     "iopub.status.busy": "2021-05-20T12:16:54.072724Z",
     "iopub.status.idle": "2021-05-20T12:16:54.079387Z",
     "shell.execute_reply": "2021-05-20T12:16:54.078289Z",
     "shell.execute_reply.started": "2021-05-20T12:16:54.073019Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "globals().pop(\"train_seq\", None)\n",
    "globals().pop(\"train_mask\", None)\n",
    "globals().pop(\"train_y\", None)\n",
    "gc.collect()\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "globals().pop(\"train_data\", None)\n",
    "globals().pop(\"train_sampler\", None)\n",
    "gc.collect()\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "globals().pop(\"val_seq\", None)\n",
    "globals().pop(\"val_mask\", None)\n",
    "globals().pop(\"val_y\", None)\n",
    "gc.collect()\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
    "globals().pop(\"val_data\", None)\n",
    "globals().pop(\"val_sampler\", None)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">7. Model Architecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ReduceMatrixModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReduceMatrixModel, self).__init__()\n",
    "        \n",
    "        # First Convolutional Layer: Reduce size from (2537, 2172)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Adjust based on the final conv layer output size (256 * 159 * 136 = 5535744)\n",
    "        self.fc1 = nn.Linear(256 * 159 * 136, 512)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.shape) # -> (batch_size, 1, 2537, 2172)\n",
    "        x = F.relu(self.conv1(x))  # -> (batch_size, 32, 1269, 1086)\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.conv2(x))  # -> (batch_size, 64, 635, 543)\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.conv3(x))  # -> (batch_size, 128, 318, 272)\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.conv4(x))  # -> (batch_size, 256, 159, 136)\n",
    "        print(x.shape)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # -> (batch_size, 256 * 159 * 136 = 5535744)\n",
    "        print(x.shape)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))  # -> (batch_size, 512)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "# Definir la arquitectura BERT con la reducci칩n PCA incluida\n",
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert, vocab_size):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert \n",
    "\n",
    "        self.reduce = ReduceMatrixModel()\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # ReLU activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Dense layer 1\n",
    "        self.fc1 = nn.Linear(512, 512)\n",
    "        \n",
    "        # Dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512, vocab_size)\n",
    "\n",
    "        # Softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, seq_input: torch.Tensor, mask: torch.Tensor):\n",
    "        mask = torch.ones(512)\n",
    "        print(0, f\"seq_input: {seq_input.shape}\")\n",
    "        print(1, f\"mask: {mask.shape}\")\n",
    "        new_seq_input = []\n",
    "        for i in range(seq_input.shape[0]):\n",
    "            a = seq_input[i]\n",
    "            print(a.shape)\n",
    "            a = self.reduce(torch.tensor([[a]]).float())\n",
    "            new_seq_input.append(a)\n",
    "        print(2, new_seq_input.shape)\n",
    "        outputs = self.bert(inputs_embeds=seq_input, attention_mask=mask, return_dict=True)\n",
    "\n",
    "        # Usar el 칰ltimo estado oculto\n",
    "        x = outputs.last_hidden_state\n",
    "        \n",
    "        # Pasar por capas densas\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Aplicar softmax\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Inicializar el modelo con BERT y vocab_size\n",
    "model = BERT_Arch(bert, vocab_size)\n",
    "\n",
    "# Mover el modelo a la GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Definir el optimizador y la funci칩n de p칠rdida\n",
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "# N칰mero de 칠pocas de entrenamiento\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">8. Fine - Tune</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# Define the BLEU score function for a single prediction and reference\n",
    "def calculate_bleu(preds, references):\n",
    "    smoothie = SmoothingFunction().method4  # Smoothing method to avoid zero scores for short sentences\n",
    "    score = sentence_bleu([references], preds, smoothing_function=smoothie)\n",
    "    return score\n",
    "\n",
    "# Function to convert token ids back to words (predictions and labels)\n",
    "def decode_predictions(predictions, tokenizer):\n",
    "    # Convert token IDs to tokens (words) using the tokenizer's decode method\n",
    "    return [tokenizer.decode(pred, skip_special_tokens=True) for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        model: torch.nn.Module, \n",
    "        train_loader: DataLoader, \n",
    "        optimizer: torch.optim.Optimizer, \n",
    "        criterion: torch.nn.Module, \n",
    "        device: torch.device, \n",
    "        epoch: int):\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (inputs, mask, labels) in enumerate(train_loader):\n",
    "        inputs, mask, labels = inputs.to(device), mask.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs, mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass y optimizaci칩n\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # C치lculo de m칠tricas\n",
    "        running_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Logs en consola\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch}], Step [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Logs en W&B\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"batch_idx\": batch_idx,\n",
    "            \"loss\": loss.item(),\n",
    "            \"accuracy_batch\": 100 * correct / total\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "    \n",
    "    # Logs por epoch en W&B\n",
    "    wandb.log({\n",
    "        \"epoch_loss\": epoch_loss,\n",
    "        \"epoch_accuracy\": epoch_accuracy,\n",
    "        \"epoch\": epoch\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "        model: torch.nn.Module, \n",
    "        val_loader: DataLoader, \n",
    "        criterion: torch.nn.Module, \n",
    "        device: torch.device, \n",
    "        epoch: int):\n",
    "    \n",
    "    model.eval()  # Establecemos el modelo en modo evaluaci칩n\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():  # No necesitamos calcular gradientes en evaluaci칩n\n",
    "        for batch_idx, (inputs, mask, labels) in enumerate(val_loader):\n",
    "            inputs, mask, labels = inputs.to(device), mask.to(device), labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(inputs, mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # C치lculo de m칠tricas\n",
    "            running_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Logs en consola\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Eval Step [{batch_idx}/{len(val_loader)}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "            # Logs en W&B\n",
    "            wandb.log({\n",
    "                \"eval_batch_idx\": batch_idx,\n",
    "                \"eval_loss\": loss.item(),\n",
    "                \"eval_accuracy_batch\": 100 * correct / total\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    print(f\"Validation Epoch [{epoch}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "    \n",
    "    # Logs por epoch en W&B\n",
    "    wandb.log({\n",
    "        \"val_epoch_loss\": epoch_loss,\n",
    "        \"val_epoch_accuracy\": epoch_accuracy,\n",
    "        \"epoch\": epoch\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializaci칩n de variables para seguimiento del mejor modelo\n",
    "best_valid_loss = float('inf')\n",
    "best_bleu_score = 0\n",
    "\n",
    "# Listas para almacenar loss y BLEU de cada epoch\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_bleu_scores = []\n",
    "valid_bleu_scores = []\n",
    "\n",
    "# Configuraci칩n de hiperpar치metros\n",
    "wandb.config = {\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "}\n",
    "\n",
    "# Ciclo de entrenamiento y evaluaci칩n por cada epoch\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    train_loss, train_bleu = train(model, train_dataloader, optimizer, cross_entropy, device, epoch)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    valid_loss, valid_bleu = evaluate(model, val_dataloader, cross_entropy, device, epoch)\n",
    "\n",
    "    # Guardar el mejor modelo basado en la validaci칩n de loss\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(f\"Modelo guardado en epoch {epoch + 1} con loss de validaci칩n {valid_loss:.4f}\")\n",
    "\n",
    "    # Guardar loss y BLEU para entrenamiento y validaci칩n\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    train_bleu_scores.append(train_bleu)\n",
    "    valid_bleu_scores.append(valid_bleu)\n",
    "\n",
    "    # Mostrar estad칤sticas de entrenamiento y validaci칩n\n",
    "    print(f\"Training Loss: {train_loss:.4f} | Training BLEU: {train_bleu:.4f}\")\n",
    "    print(f\"Validation Loss: {valid_loss:.4f} | Validation BLEU: {valid_bleu:.4f}\")\n",
    "    \n",
    "    # Registros de la 칠poca en W&B\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_bleu\": train_bleu,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"valid_bleu\": valid_bleu\n",
    "    })\n",
    "\n",
    "# Finaliza el seguimiento de W&B\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:24:47.832686Z",
     "iopub.status.busy": "2021-05-20T12:24:47.832372Z",
     "iopub.status.idle": "2021-05-20T12:24:48.147778Z",
     "shell.execute_reply": "2021-05-20T12:24:48.147016Z",
     "shell.execute_reply.started": "2021-05-20T12:24:47.832657Z"
    }
   },
   "outputs": [],
   "source": [
    "#load weights of best model\n",
    "path = 'best_model.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">9. Make Predictions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:25:07.436008Z",
     "iopub.status.busy": "2021-05-20T12:25:07.435685Z",
     "iopub.status.idle": "2021-05-20T12:25:08.019816Z",
     "shell.execute_reply": "2021-05-20T12:25:08.018976Z",
     "shell.execute_reply.started": "2021-05-20T12:25:07.435979Z"
    }
   },
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:25:23.838719Z",
     "iopub.status.busy": "2021-05-20T12:25:23.838389Z",
     "iopub.status.idle": "2021-05-20T12:25:23.852193Z",
     "shell.execute_reply": "2021-05-20T12:25:23.850795Z",
     "shell.execute_reply.started": "2021-05-20T12:25:23.838691Z"
    }
   },
   "outputs": [],
   "source": [
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 863500,
     "sourceId": 1471804,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30096,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
