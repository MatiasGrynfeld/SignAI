{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">1. Import Required Libraries & Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModel, BertTokenizer\n",
    "import random\n",
    "\n",
    "#specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if Pytorch is using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 1,\n",
       " 0,\n",
       " <torch.cuda.device at 0x7efc1846aa10>,\n",
       " 'NVIDIA RTX 3500 Ada Generation Laptop GPU',\n",
       " device(type='cuda'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available(), torch.cuda.device_count(), torch.cuda.current_device(), torch.cuda.device(0), torch.cuda.get_device_name(0), device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos = pd.read_csv(\"/app/AI-Module/Resources/Datasets/how2sign.csv\")\n",
    "#df_videos = pd.read_csv(\"C:/Users/48519558/Desktop/SignAI-ML/AI-Module/Resources/Datasets/how2sign.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_list = pd.read_pickle(\"/app/AI-Module/Resources/Datasets/how2sign_points.pkl\")\n",
    "#point_list = pd.read_pickle(\"C:/Users/48519558/Desktop/SignAI-ML/AI-Module/Resources/Datasets/how2sign_points.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(point_list.iloc[0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos[\"points\"] = point_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = df_videos['points'].apply(lambda x: len(x)).max()\n",
    "df_videos.head(), max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(max_frames, pointSeries: pd.Series):\n",
    "    for i in range(len(pointSeries)):\n",
    "        current_length = len(pointSeries[i])\n",
    "        if current_length < max_frames:\n",
    "            padding = np.full(\n",
    "                (max_frames - current_length, 2172), \n",
    "                -1\n",
    "            )\n",
    "            padding[:, 3::4] = 0\n",
    "            pointSeries[i] = np.concatenate((pointSeries[i], padding), axis=0)\n",
    "\n",
    "    return pointSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos['points'] = add_padding(max_len, df_videos['points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df_videos['points'].to_frame()\n",
    "y_df = df_videos['translation'].to_frame()\n",
    "seed = 31991\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=(100/500), random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=(100/400), random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(), y_train.head(), X_val.head(), y_val.head(), X_test.head(), y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">3. Import Bert - base- uncased</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T11:49:24.18724Z",
     "iopub.status.busy": "2021-05-20T11:49:24.186902Z",
     "iopub.status.idle": "2021-05-20T11:50:15.137513Z",
     "shell.execute_reply": "2021-05-20T11:50:15.135994Z",
     "shell.execute_reply.started": "2021-05-20T11:49:24.187212Z"
    }
   },
   "outputs": [],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_label_train = tokenizer.batch_encode_plus(\n",
    "    y_train['translation'].tolist(),\n",
    "    padding = True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_label_val = tokenizer.batch_encode_plus(\n",
    "    y_val['translation'].tolist(),\n",
    "    padding = True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_label_test = tokenizer.batch_encode_plus(\n",
    "    y_test['translation'].tolist(),\n",
    "    padding = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u><h2 style=\"font-size:170%; font-family:cursive;\">What is the maximum sequence length of the input?</h2></u>\n",
    "\n",
    "<p style=\"font-size:150%; font-family:verdana;\">The maximum sequence length of the input = 512</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">5. List to Tensors</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_mask_from_points(seq_tensor):\n",
    "    mask = torch.ones(seq_tensor.shape, dtype=torch.long)\n",
    "    missing_data = (seq_tensor[..., :3] == -1).all(dim=-1) & (seq_tensor[..., 3] == 0)\n",
    "    mask[missing_data] = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:16:52.707444Z",
     "iopub.status.busy": "2021-05-20T12:16:52.707085Z",
     "iopub.status.idle": "2021-05-20T12:16:52.744645Z",
     "shell.execute_reply": "2021-05-20T12:16:52.743449Z",
     "shell.execute_reply.started": "2021-05-20T12:16:52.707415Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert lists to tensors\n",
    "\n",
    "train_seq = torch.stack([torch.tensor(seq) for seq in X_train['points'].tolist()])\n",
    "train_mask = create_attention_mask_from_points(train_seq)\n",
    "train_y = tokens_label_train['input_ids']\n",
    "\n",
    "val_seq = torch.stack([torch.tensor(seq) for seq in X_val['points'].tolist()])\n",
    "val_mask = create_attention_mask_from_points(val_seq)\n",
    "val_y = tokens_label_val['input_ids']\n",
    "\n",
    "test_seq = torch.stack([torch.tensor(seq) for seq in X_test['points'].tolist()])\n",
    "test_mask = create_attention_mask_from_points(test_seq)\n",
    "test_y = tokens_label_test['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">6. Data Loader</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:16:54.073069Z",
     "iopub.status.busy": "2021-05-20T12:16:54.072724Z",
     "iopub.status.idle": "2021-05-20T12:16:54.079387Z",
     "shell.execute_reply": "2021-05-20T12:16:54.078289Z",
     "shell.execute_reply.started": "2021-05-20T12:16:54.073019Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">7. Model Architecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert, vocab_size):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert \n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # ReLU activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Dense layer 1\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        \n",
    "        # Dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512, vocab_size)  # Use tokenizer's vocab size\n",
    "\n",
    "        # Softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, seq_input, mask):\n",
    "        outputs = self.bert(seq_input, attention_mask=mask, return_dict=False)\n",
    "        \n",
    "        # Use the last hidden state for each token (outputs[0])\n",
    "        x = self.fc1(outputs[0])  # (batch_size, sequence_length, 512)\n",
    "\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)  # (batch_size, sequence_length, vocab_size)\n",
    "        \n",
    "        # Apply softmax activation (for each token in the sequence)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu(preds, labels):\n",
    "    # Aquí puedes usar la función BLEU de NLTK o cualquier otra implementación de BLEU\n",
    "    # Convertir las predicciones y los labels a listas de tokens\n",
    "    pred_tokens = torch.argmax(preds, dim=-1).tolist()\n",
    "    label_tokens = labels.tolist()\n",
    "    \n",
    "    # Calcular BLEU usando, por ejemplo, nltk\n",
    "    bleu_score = nltk.translate.bleu_score.sentence_bleu([label_tokens], pred_tokens)\n",
    "    \n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert, vocab_size)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),lr = 1e-5) \n",
    "\n",
    "# Define the loss function\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">8. Fine - Tune</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_hyperparameters(hyperparameters):\n",
    "    new_hyperparameters = hyperparameters.copy()\n",
    "    new_hyperparameters['learning_rate'] = hyperparameters['learning_rate'] * random.uniform(0.8, 1.2)\n",
    "    return new_hyperparameters\n",
    "\n",
    "\n",
    "def train(hyperparameters):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0.0\n",
    "    total_bleu = 0.0\n",
    "\n",
    "    # Loop through batches of training data (asegúrate de tener un dataloader)\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        \n",
    "        input_ids, attention_mask, labels = batch  # Extract input and labels\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = cross_entropy(outputs.view(-1, vocab_size), labels.view(-1))\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss and BLEU score for the batch\n",
    "        total_loss += loss.item()\n",
    "        bleu_score = compute_bleu(outputs, labels)  # Implementar la función compute_bleu\n",
    "        total_bleu += bleu_score\n",
    "\n",
    "    # Calculate average loss and BLEU score for the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    avg_bleu = total_bleu / len(train_dataloader)\n",
    "\n",
    "    return avg_loss, avg_bleu\n",
    "\n",
    "\n",
    "def evaluate(hyperparameters):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    total_bleu = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dataloader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = cross_entropy(outputs.view(-1, vocab_size), labels.view(-1))\n",
    "            \n",
    "            # Accumulate loss and BLEU score\n",
    "            total_loss += loss.item()\n",
    "            bleu_score = compute_bleu(outputs, labels)  # Implementar la función compute_bleu\n",
    "            total_bleu += bleu_score\n",
    "\n",
    "    # Calculate average loss and BLEU score for the validation set\n",
    "    avg_loss = total_loss / len(valid_dataloader)\n",
    "    avg_bleu = total_bleu / len(valid_dataloader)\n",
    "\n",
    "    return avg_loss, avg_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración inicial\n",
    "best_valid_loss = float('inf')\n",
    "best_bleu_score = 0\n",
    "train_losses, valid_losses = [], []\n",
    "train_bleu_scores, valid_bleu_scores = []\n",
    "\n",
    "# Simulación de Population Based Training con múltiples ensayos\n",
    "num_trials = 8\n",
    "trials = [{'hyperparameters': hyperparameters.copy(), 'state': None} for _ in range(num_trials)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    for trial_id, trial in enumerate(trials):\n",
    "        # Restaurar el estado del modelo si existe (evitando reentrenamiento desde cero)\n",
    "        if trial['state']:\n",
    "            model.load_state_dict(trial['state'])\n",
    "        \n",
    "        # Entrenar y evaluar el modelo con los hiperparámetros actuales\n",
    "        train_loss, train_bleu = train(trial['hyperparameters'])\n",
    "        valid_loss, valid_bleu = evaluate(trial['hyperparameters'])\n",
    "        \n",
    "        # Si la pérdida de validación mejora, actualizar el mejor modelo\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_bleu_score = valid_bleu\n",
    "            torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "        \n",
    "        # Guardar estado y resultados\n",
    "        trial['state'] = model.state_dict().copy()\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        train_bleu_scores.append(train_bleu)\n",
    "        valid_bleu_scores.append(valid_bleu)\n",
    "        \n",
    "        # Perturbar los hiperparámetros en los ensayos de bajo rendimiento\n",
    "        if valid_loss > best_valid_loss * 1.1:\n",
    "            print(f'\\nTrial {trial_id} underperforming, copying weights from better performing trials...')\n",
    "            good_trial = random.choice([t for t in trials if t['hyperparameters'] != trial['hyperparameters']])\n",
    "            trial['state'] = good_trial['state']\n",
    "            trial['hyperparameters'] = perturb_hyperparameters(good_trial['hyperparameters'])\n",
    "        \n",
    "        # Imprimir estadísticas de entrenamiento\n",
    "        print(f'Trial {trial_id} | Training Loss: {train_loss:.3f} | Training BLEU: {train_bleu:.3f}')\n",
    "        print(f'Validation Loss: {valid_loss:.3f} | Validation BLEU: {valid_bleu:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:24:47.832686Z",
     "iopub.status.busy": "2021-05-20T12:24:47.832372Z",
     "iopub.status.idle": "2021-05-20T12:24:48.147778Z",
     "shell.execute_reply": "2021-05-20T12:24:48.147016Z",
     "shell.execute_reply.started": "2021-05-20T12:24:47.832657Z"
    }
   },
   "outputs": [],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">9. Make Predictions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:25:07.436008Z",
     "iopub.status.busy": "2021-05-20T12:25:07.435685Z",
     "iopub.status.idle": "2021-05-20T12:25:08.019816Z",
     "shell.execute_reply": "2021-05-20T12:25:08.018976Z",
     "shell.execute_reply.started": "2021-05-20T12:25:07.435979Z"
    }
   },
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:25:23.838719Z",
     "iopub.status.busy": "2021-05-20T12:25:23.838389Z",
     "iopub.status.idle": "2021-05-20T12:25:23.852193Z",
     "shell.execute_reply": "2021-05-20T12:25:23.850795Z",
     "shell.execute_reply.started": "2021-05-20T12:25:23.838691Z"
    }
   },
   "outputs": [],
   "source": [
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 863500,
     "sourceId": 1471804,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30096,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
