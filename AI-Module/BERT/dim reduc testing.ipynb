{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizer\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '0.npy'\n",
    "item_with_index = np.load(file, allow_pickle=True)\n",
    "item = item_with_index[0].astype(np.float16)\n",
    "max_len = 2537\n",
    "def add_padding(max_frames, item):\n",
    "    current_length = item.shape[0]\n",
    "    if current_length < max_frames:\n",
    "        padding = np.full(\n",
    "            (max_frames - current_length, 2172), \n",
    "            -1,\n",
    "            dtype=np.float16\n",
    "        )\n",
    "        padding[:, 3::4] = 0\n",
    "        item = np.concatenate((item, padding), axis=0)\n",
    "    return item\n",
    "matrix = add_padding(max_len, item)\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Generar la matriz y centrar los datos restando la media de cada columna\n",
    "matrix_meaned = matrix - np.mean(matrix, axis=0)\n",
    "\n",
    "# Paso 2: Calcular la matriz de covarianza\n",
    "cov_matrix = np.cov(matrix_meaned, rowvar=False)\n",
    "\n",
    "# Paso 3: Calcular los valores y vectores propios\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "# Paso 4: Filtrar valores propios negativos o muy cercanos a cero\n",
    "eigenvalues = eigenvalues[eigenvalues > 1e-10]  # Filtramos los valores muy pequeños o negativos\n",
    "\n",
    "# Ordenar los valores propios en orden descendente\n",
    "sorted_eigenvalues = np.sort(eigenvalues)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5: Graficar los valores propios en un gráfico de barras verticales (bar)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(range(len(sorted_eigenvalues)), sorted_eigenvalues, color='blue')\n",
    "plt.xlabel('Component Number')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.title('PCA Eigenvalues Ordered by Importance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PCA()\n",
    "pc.fit(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Principal Component Analysis')\n",
    "plt.plot(pc.explained_variance_ratio_)\n",
    "print(pc.explained_variance_ratio_)\n",
    "plt.legend(['Explained Variance'])\n",
    "plt.xlabel('N Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PCA(n_components=1)\n",
    "new_matrix = pc.fit_transform(matrix)\n",
    "print(\"Original matrix shape:\", matrix.shape)\n",
    "print(\"New matrix shape after PCA:\", new_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2: Graficar la varianza explicada por cada componente principal\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(1, len(pc.explained_variance_ratio_) + 1), pc.explained_variance_ratio_, color='blue')\n",
    "print(pc.explained_variance_ratio_)\n",
    "plt.title('Explained Variance Ratio by Principal Component')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ReduceMatrixModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReduceMatrixModel, self).__init__()\n",
    "        \n",
    "        # Capas convolucionales para reducir de (1, 2537, 2172) a (256, 8, 6)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=1)   # -> (batch_size, 32, 1269, 1086)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)                           # -> (batch_size, 64, 635, 543)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)                          # -> (batch_size, 128, 318, 272)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)                         # -> (batch_size, 256, 159, 136)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1)                         # -> (batch_size, 256, 80, 68)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1)                         # -> (batch_size, 256, 40, 34)\n",
    "        self.conv7 = nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1)                         # -> (batch_size, 256, 20, 17)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1)                         # -> (batch_size, 256, 10, 9)\n",
    "        self.conv9 = nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1)                         # -> (batch_size, 256, 5, 5)\n",
    "\n",
    "        # Capas lineales para reducir de 256*5*5 a 512*768\n",
    "        self.fc1 = nn.Linear(256 * 5 * 5, 512 * 768)  # -> (batch_size, 512*768)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Aplicar convoluciones\n",
    "        x = F.relu(self.conv1(x))  # -> (batch_size, 32, 1269, 1086)\n",
    "        x = F.relu(self.conv2(x))  # -> (batch_size, 64, 635, 543)\n",
    "        x = F.relu(self.conv3(x))  # -> (batch_size, 128, 318, 272)\n",
    "        x = F.relu(self.conv4(x))  # -> (batch_size, 256, 159, 136)\n",
    "        x = F.relu(self.conv5(x))  # -> (batch_size, 256, 80, 68)\n",
    "        x = F.relu(self.conv6(x))  # -> (batch_size, 256, 40, 34)\n",
    "        x = F.relu(self.conv7(x))  # -> (batch_size, 256, 20, 17)\n",
    "        x = F.relu(self.conv8(x))  # -> (batch_size, 256, 10, 9)\n",
    "        x = F.relu(self.conv9(x))  # -> (batch_size, 256, 5, 5)\n",
    "        \n",
    "        # Aplanar el tensor para pasar por la capa lineal\n",
    "        x = x.view(x.size(0), -1)  # -> (batch_size, 256*5*5)\n",
    "        \n",
    "        # Pasar por la capa lineal\n",
    "        x = self.fc1(x)  # -> (batch_size, 512*768)\n",
    "        \n",
    "        # Reorganizar el tensor en la forma deseada (batch_size, 512, 768)\n",
    "        x = x.view(x.size(0), 512, 768)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Instanciar el modelo y moverlo al dispositivo\n",
    "reduce = ReduceMatrixModel().to(device)\n",
    "reduce = reduce.half()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert, vocab_size, max_len=512):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert \n",
    "        self.reduce = reduce\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # Dense layer (Output layer)\n",
    "        self.fc = nn.Linear(bert.config.hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, seq_input: torch.Tensor):\n",
    "        # Aplicar reducción de dimensionalidad\n",
    "        seq_input = seq_input.unsqueeze(1)\n",
    "        print(seq_input.shape)\n",
    "        seq_input = self.reduce(seq_input)  # (batch_size, 512)\n",
    "        print(seq_input.shape)\n",
    "        # Crear máscara de atención\n",
    "        attention_mask = torch.ones(seq_input.shape[0], seq_input.shape[1], seq_input.shape[2]).to(seq_input.device).to(torch.half)\n",
    "        print(seq_input.shape == attention_mask.shape)\n",
    "        print(seq_input.shape, attention_mask.shape, seq_input.dtype, attention_mask.dtype)\n",
    "        print(seq_input[0][0])\n",
    "        outputs = self.bert(inputs_embeds=seq_input, attention_mask=attention_mask, return_dict=True)\n",
    "        print(\"salio\")\n",
    "        x = outputs.last_hidden_state  # Usar el último estado oculto\n",
    "\n",
    "        # Pasar por la capa densa\n",
    "        logits = self.fc(x)  # logits tiene forma (batch_size, 512, vocab_size)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    def generate(self, input_ids, max_length):\n",
    "        self.eval()\n",
    "        generated_tokens = []\n",
    "\n",
    "        # Inicializar el estado de entrada para generación\n",
    "        for _ in range(max_length):\n",
    "            outputs = self.forward(input_ids)\n",
    "            next_token = torch.argmax(outputs[:, -1, :], dim=-1)  # Obtener el token más probable\n",
    "            generated_tokens.append(next_token.item())\n",
    "            \n",
    "            # Actualizar input_ids para el siguiente token\n",
    "            input_ids = torch.cat([input_ids, next_token.unsqueeze(1)], dim=1)\n",
    "\n",
    "            # Salir si se alcanza el token de fin de secuencia\n",
    "            if next_token.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "        return generated_tokens\n",
    "\n",
    "# Inicializar el modelo con BERT y vocab_size\n",
    "model = BERT_Arch(bert, vocab_size)\n",
    "\n",
    "# Mover el modelo a la GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(torch.tensor([matrix]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tokens = torch.argmax(outputs, dim=-1)  # (batch_size, seq_length)\n",
    "predicted_tokens = predicted_tokens[0].tolist()\n",
    "decoded_text = tokenizer.decode(predicted_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Texto generado:\", decoded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
