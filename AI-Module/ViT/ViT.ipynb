{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">1. Import Required Libraries & Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "base_path = Path(os.getcwd()).parent / 'Modules'\n",
    "sys.path.append(str(base_path))\n",
    "from KeyFrameExtractorClass import KeyFrameExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos = pd.DataFrame(columns=['video_name', 'video_path', 'translation'])\n",
    "videos_path = Path(os.getcwd()).parent / 'Resources' / 'Datasets' / 'Videos'\n",
    "df_translation = pd.read_csv(str(videos_path.parent.parent / 'Translations' / 'how2sign_train.csv'), sep='\\t', usecols=['VIDEO_NAME', 'SENTENCE']).groupby('VIDEO_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>video_path</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-00cp1iGiDw-5-rgb_front</td>\n",
       "      <td>c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...</td>\n",
       "      <td>If you like to find more about my services you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-08ZGCviCm4-5-rgb_front</td>\n",
       "      <td>c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...</td>\n",
       "      <td>Hello welcome my name is Julio Nutt and I am a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1KpdDGPCq4-5-rgb_front</td>\n",
       "      <td>c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...</td>\n",
       "      <td>All right, the drink we're about to make is ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1XUnputrgk-5-rgb_front</td>\n",
       "      <td>c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...</td>\n",
       "      <td>Okay, another thing that for me is important. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3sFcDBFxc8-5-rgb_front</td>\n",
       "      <td>c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...</td>\n",
       "      <td>All right, we're ready to start our fire. What...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                video_name                                         video_path  \\\n",
       "0  -00cp1iGiDw-5-rgb_front  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...   \n",
       "0  -08ZGCviCm4-5-rgb_front  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...   \n",
       "0  -1KpdDGPCq4-5-rgb_front  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...   \n",
       "0  -1XUnputrgk-5-rgb_front  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...   \n",
       "0  -3sFcDBFxc8-5-rgb_front  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...   \n",
       "\n",
       "                                         translation  \n",
       "0  If you like to find more about my services you...  \n",
       "0  Hello welcome my name is Julio Nutt and I am a...  \n",
       "0  All right, the drink we're about to make is ca...  \n",
       "0  Okay, another thing that for me is important. ...  \n",
       "0  All right, we're ready to start our fire. What...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for video in os.listdir(str(videos_path)):\n",
    "    video_path = videos_path / video\n",
    "    video_name = video.removeprefix('filtered_').removesuffix('.mp4')\n",
    "    sentence = df_translation.get_group(video_name)['SENTENCE'].str.cat(sep=' ')\n",
    "    new_row = pd.DataFrame({'video_name': [video_name], 'video_path': [video_path], 'translation': [sentence]})\n",
    "    df_videos = pd.concat([df_videos, new_row])\n",
    "df_videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from transformers import ViTModel, GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "\n",
    "#specify GPU\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if Pytorch is using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available(), torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count(), \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;241m0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(\u001b[38;5;241m0\u001b[39m), device\n",
      "File \u001b[1;32mc:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:878\u001b[0m, in \u001b[0;36mcurrent_device\u001b[1;34m()\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    877\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[1;32mc:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m     )\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available(), torch.cuda.device_count(), torch.cuda.current_device(), torch.cuda.device(0), torch.cuda.get_device_name(0), device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_df = df_videos['video_path'].to_frame()\n",
    "y_df = df_videos['translation'].to_frame()\n",
    "seed = 31991\n",
    "batch_size = 32\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=(100/500), random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=(100/400), random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                          video_path\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...,\n",
       "                                          translation\n",
       " 0  Hi! Let it drip off a little bit, put it on a ...\n",
       " 0  I'm Ivan Madar. Skiing is done from your waste...\n",
       " 0  Hi, this Sean Hobson, and right now we're work...\n",
       " 0  Developing reading skills isn't it important t...\n",
       " 0  We have 2 different receipts to show you a pea...,\n",
       "                                           video_path\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...,\n",
       "                                          translation\n",
       " 0  Sponges and the wire tool are tools you use ev...\n",
       " 0  So, being able to paint a face with acrylics, ...\n",
       " 0  Your skin is your largest organ and it will ab...\n",
       " 0  Now we've learned how to hit a ball inside, we...\n",
       " 0  All right, folks, in this clip I'm going to te...,\n",
       "                                           video_path\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...\n",
       " 0  c:\\Users\\matia\\OneDrive\\Escritorio\\SignAI-ML\\A...,\n",
       "                                          translation\n",
       " 0  With your damp book up on edge, with all of th...\n",
       " 0  Hi, I'm Casey I'm with Elements University. In...\n",
       " 0  Now we are going to go over some measuring rul...\n",
       " 0  So, as we drop into this dragon position, a lo...\n",
       " 0  The marine organism we're going to identify no...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(), y_train.head(), X_val.head(), y_val.head(), X_test.head(), y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 1), (300, 1), (100, 1), (100, 1), (100, 1), (100, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">3. Import ViT</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T11:49:24.18724Z",
     "iopub.status.busy": "2021-05-20T11:49:24.186902Z",
     "iopub.status.idle": "2021-05-20T11:50:15.137513Z",
     "shell.execute_reply": "2021-05-20T11:50:15.135994Z",
     "shell.execute_reply.started": "2021-05-20T11:49:24.187212Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_label_train = tokenizer(\n",
    "    y_train['translation'].tolist(),\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "tokens_label_val = tokenizer(\n",
    "    y_val['translation'].tolist(),\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "tokens_label_test = tokenizer(\n",
    "    y_test['translation'].tolist(),\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">5. List to Tensors</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:16:52.707444Z",
     "iopub.status.busy": "2021-05-20T12:16:52.707085Z",
     "iopub.status.idle": "2021-05-20T12:16:52.744645Z",
     "shell.execute_reply": "2021-05-20T12:16:52.743449Z",
     "shell.execute_reply.started": "2021-05-20T12:16:52.707415Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train['token_ids'] = tokens_label_train['input_ids'].tolist()\n",
    "y_val['token_ids'] = tokens_label_val['input_ids'].tolist()\n",
    "y_test['token_ids'] = tokens_label_test['input_ids'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">7. Model Architecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert, vocab_size, max_len=512):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert \n",
    "        self.reduce = reduce\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # Dense layer (Output layer)\n",
    "        self.fc = nn.Linear(bert.config.hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, seq_input: torch.Tensor):\n",
    "        # # Aplicar reducción de dimensionalidad\n",
    "        # seq_input = seq_input.unsqueeze(1)\n",
    "        # print(seq_input.shape)\n",
    "        # seq_input = self.reduce(seq_input)  # (batch_size, 512)\n",
    "        # print(seq_input.shape)\n",
    "        # # Crear máscara de atención\n",
    "        # attention_mask = torch.ones(seq_input.shape[0], seq_input.shape[1]).to(seq_input.device)\n",
    "        # print(seq_input.shape == attention_mask.shape)\n",
    "        seq_input = torch.ones(32,512,512,512).half().to(device)\n",
    "        attention_mask = torch.ones(32,512,512,512).half().to(device)\n",
    "        print(seq_input.shape, attention_mask.shape)\n",
    "        outputs = self.bert(inputs_embeds=seq_input, attention_mask=attention_mask, return_dict=True)\n",
    "        print(\"salio\")\n",
    "        x = outputs.last_hidden_state  # Usar el último estado oculto\n",
    "\n",
    "        # Pasar por la capa densa\n",
    "        logits = self.fc(x)  # logits tiene forma (batch_size, 512, vocab_size)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    def generate(self, input_ids, max_length):\n",
    "        self.eval()\n",
    "        generated_tokens = []\n",
    "\n",
    "        # Inicializar el estado de entrada para generación\n",
    "        for _ in range(max_length):\n",
    "            outputs = self.forward(input_ids)\n",
    "            next_token = torch.argmax(outputs[:, -1, :], dim=-1)  # Obtener el token más probable\n",
    "            generated_tokens.append(next_token.item())\n",
    "            \n",
    "            # Actualizar input_ids para el siguiente token\n",
    "            input_ids = torch.cat([input_ids, next_token.unsqueeze(1)], dim=1)\n",
    "\n",
    "            # Salir si se alcanza el token de fin de secuencia\n",
    "            if next_token.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "        return generated_tokens\n",
    "\n",
    "# Inicializar el modelo con BERT y vocab_size\n",
    "model = BERT_Arch(bert, vocab_size)\n",
    "\n",
    "# Mover el modelo a la GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Definir el optimizador y la función de pérdida\n",
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "# Número de épocas de entrenamiento\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">8. Fine - Tune</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def calculate_bleu(preds, references):\n",
    "    smoothie = SmoothingFunction().method4  # Smoothing method to avoid zero scores for short sentences\n",
    "    # Calcula el BLEU score para cada predicción en el batch\n",
    "    scores = []\n",
    "    for pred, ref in zip(preds, references):\n",
    "        score = sentence_bleu([ref], pred, smoothing_function=smoothie)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "# Function to convert token ids back to words (predictions and labels)\n",
    "def decode_predictions(predictions, tokenizer):\n",
    "    decoded_preds = []\n",
    "    for pred in predictions:\n",
    "        # Convert token IDs to tokens (words) using the tokenizer's decode method\n",
    "        decoded = tokenizer.decode(pred, skip_special_tokens=True)\n",
    "        decoded_preds.append(decoded)\n",
    "    return decoded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        model: torch.nn.Module, \n",
    "        train_loader: DataLoader, \n",
    "        optimizer: torch.optim.Optimizer, \n",
    "        criterion: torch.nn.Module, \n",
    "        device: torch.device, \n",
    "        epoch: int):\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_refs = []\n",
    "\n",
    "    for batch_idx, (inputs, mask, labels) in enumerate(train_loader):\n",
    "        inputs, mask, labels = inputs.to(device), mask.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)  # (batch_size, seq_length, vocab_size)\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
    "        \n",
    "        # Backward pass y optimización\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Cálculo de métricas\n",
    "        running_loss += loss.item()\n",
    "        total += labels.numel()\n",
    "        _, predicted = torch.max(outputs.view(-1, outputs.size(-1)), 1)\n",
    "        correct += (predicted == labels.view(-1)).sum().item()\n",
    "\n",
    "        # Decodificación para BLEU\n",
    "        all_preds.extend(predicted.tolist())\n",
    "        all_refs.extend(labels.view(-1).tolist())\n",
    "        \n",
    "        # Logs en consola\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch}], Step [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Logs en W&B\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"batch_idx\": batch_idx,\n",
    "            \"loss\": loss.item(),\n",
    "            \"accuracy_batch\": 100 * correct / total\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "\n",
    "    # Calcular BLEU\n",
    "    train_bleu = calculate_bleu(all_preds, all_refs)\n",
    "\n",
    "    print(f\"Epoch [{epoch}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "    \n",
    "    return epoch_loss, train_bleu\n",
    "\n",
    "def evaluate(\n",
    "        model: torch.nn.Module, \n",
    "        val_loader: DataLoader, \n",
    "        criterion: torch.nn.Module, \n",
    "        device: torch.device, \n",
    "        epoch: int):\n",
    "    \n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_refs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, mask, labels) in enumerate(val_loader):\n",
    "            inputs, mask, labels = inputs.to(device), mask.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
    "            \n",
    "            # Cálculo de métricas\n",
    "            running_loss += loss.item()\n",
    "            total += labels.numel()\n",
    "            _, predicted = torch.max(outputs.view(-1, outputs.size(-1)), 1)\n",
    "            correct += (predicted == labels.view(-1)).sum().item()\n",
    "\n",
    "            # Decodificación para BLEU\n",
    "            all_preds.extend(predicted.tolist())\n",
    "            all_refs.extend(labels.view(-1).tolist())\n",
    "            \n",
    "            # Logs en consola\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Eval Step [{batch_idx}/{len(val_loader)}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "            # Logs en W&B\n",
    "            wandb.log({\n",
    "                \"eval_batch_idx\": batch_idx,\n",
    "                \"eval_loss\": loss.item(),\n",
    "                \"eval_accuracy_batch\": 100 * correct / total\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "\n",
    "    # Calcular BLEU\n",
    "    valid_bleu = calculate_bleu(all_preds, all_refs)\n",
    "\n",
    "    print(f\"Validation Epoch [{epoch}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "    \n",
    "    return epoch_loss, valid_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de variables para seguimiento del mejor modelo\n",
    "best_valid_loss = float('inf')\n",
    "best_bleu_score = 0\n",
    "\n",
    "# Listas para almacenar loss y BLEU de cada epoch\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_bleu_scores = []\n",
    "valid_bleu_scores = []\n",
    "\n",
    "# Configuración de hiperparámetros\n",
    "wandb.config = {\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "}\n",
    "\n",
    "# Ciclo de entrenamiento y evaluación por cada epoch\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    train_loss, train_bleu = train(model, train_dataloader, optimizer, cross_entropy, device, epoch)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    valid_loss, valid_bleu = evaluate(model, val_dataloader, cross_entropy, device, epoch)\n",
    "\n",
    "    # Guardar el mejor modelo basado en la validación de loss\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(f\"Modelo guardado en epoch {epoch + 1} con loss de validación {valid_loss:.4f}\")\n",
    "\n",
    "    # Guardar loss y BLEU para entrenamiento y validación\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    train_bleu_scores.append(train_bleu)\n",
    "    valid_bleu_scores.append(valid_bleu)\n",
    "\n",
    "    # Mostrar estadísticas de entrenamiento y validación\n",
    "    print(f\"Training Loss: {train_loss:.4f} | Training BLEU: {train_bleu:.4f}\")\n",
    "    print(f\"Validation Loss: {valid_loss:.4f} | Validation BLEU: {valid_bleu:.4f}\")\n",
    "    \n",
    "    # Registros de la época en W&B\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_bleu\": train_bleu,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"valid_bleu\": valid_bleu\n",
    "    })\n",
    "\n",
    "# Finaliza el seguimiento de W&B\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:24:47.832686Z",
     "iopub.status.busy": "2021-05-20T12:24:47.832372Z",
     "iopub.status.idle": "2021-05-20T12:24:48.147778Z",
     "shell.execute_reply": "2021-05-20T12:24:48.147016Z",
     "shell.execute_reply.started": "2021-05-20T12:24:47.832657Z"
    }
   },
   "outputs": [],
   "source": [
    "#load weights of best model\n",
    "path = 'best_model.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:200%; font-family:cursive; color:white;\">9. Make Predictions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:25:07.436008Z",
     "iopub.status.busy": "2021-05-20T12:25:07.435685Z",
     "iopub.status.idle": "2021-05-20T12:25:08.019816Z",
     "shell.execute_reply": "2021-05-20T12:25:08.018976Z",
     "shell.execute_reply.started": "2021-05-20T12:25:07.435979Z"
    }
   },
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-20T12:25:23.838719Z",
     "iopub.status.busy": "2021-05-20T12:25:23.838389Z",
     "iopub.status.idle": "2021-05-20T12:25:23.852193Z",
     "shell.execute_reply": "2021-05-20T12:25:23.850795Z",
     "shell.execute_reply.started": "2021-05-20T12:25:23.838691Z"
    }
   },
   "outputs": [],
   "source": [
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 863500,
     "sourceId": 1471804,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30096,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
