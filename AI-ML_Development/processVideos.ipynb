{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from KeyFrameExtractorClass import KeyFrameExtractor\n","from Points2VecClass import Point2Vec\n","import cv2\n","from VideoFormaterClass import VideoFormater"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def obtain_paths(root, extension):\n","    paths = []\n","\n","    for filename in os.listdir(root):\n","        if filename.endswith(extension):\n","            paths.append(os.path.join(root, filename))\n","    return paths"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def make_df_video(video_paths, csv_path):\n","    kfe = KeyFrameExtractor()\n","    videoFormater = VideoFormater()\n","    normalizer = Point2Vec(4)\n","    translationDf = videoFormater.csvToTranslationDf(csv_path)\n","    list_of_dicts= []\n","    for index, path in enumerate(video_paths):\n","        video = cv2.VideoCapture(path)\n","        file_name = path.split(os.path.sep)[-1].split(\".mp4\")[0]\n","        translation_filter = translationDf[\"VIDEO_NAME\"] == file_name\n","        translation = translationDf[translation_filter][\"SENTENCE\"].iloc[0]\n","        video_points = kfe.extractKeyFrames(return_frame=False, draw=False, video=video)\n","        landmarks = normalizer.land2vec(video_points)\n","        list_of_dicts.append({\"points\": landmarks, \"translation\": translation, \"id\": index})\n","    dataFrame = videoFormater.formatVideo(list_of_dicts)\n","    return dataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["root_training_vids = \"C:\\\\Users\\\\48519558\\\\Desktop\\\\SignAI-ML\\\\AI-ML_Development\\\\Resources\\\\Videos\\\\Training\"\n","root_validation_vids = \"C:\\\\Users\\\\48519558\\\\Desktop\\\\SignAI-ML\\\\AI-ML_Development\\\\Resources\\\\Videos\\\\Validation\"\n","root_test_vids = \"C:\\\\Users\\\\48519558\\\\Desktop\\\\SignAI-ML\\\\AI-ML_Development\\\\Resources\\\\Videos\\\\Test\"\n","root_translation_csv = \"C:\\\\Users\\\\48519558\\\\Desktop\\\\SignAI-ML\\\\AI-ML_Development\\\\Resources\\\\Translations\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["training_vids = obtain_paths(root_training_vids, '.mp4')\n","validation_vids = obtain_paths(root_validation_vids, '.mp4')\n","test_vids = obtain_paths(root_test_vids, '.mp4')\n","translation_csv = obtain_paths(root_translation_csv, '.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def processVideos(all_paths, all_csv_paths, file_names):\n","    for video_paths, csv_path, file_name in zip(all_paths, all_csv_paths, file_names):\n","        if len(video_paths) == 0:\n","            continue\n","        df = make_df_video(video_paths, csv_path)\n","        videoFormater = VideoFormater()\n","        videoFormater.concatAndExportVideos(df, file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["processVideos([test_vids, training_vids, validation_vids],[translation_csv[2], translation_csv[2], translation_csv[2]],[\"test_vids.csv\", \"train_vids.csv\", \"val_vids.csv\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["videoFormater = VideoFormater()\n","TestVidsPath = \"C:\\\\Users\\\\48519558\\\\Desktop\\\\SignAI-ML\\\\AI-ML_Development\\\\test_vids.csv\"\n","TestsVids = videoFormater.csvToDfsVid(TestVidsPath)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["TestsVids[0]"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":2}
